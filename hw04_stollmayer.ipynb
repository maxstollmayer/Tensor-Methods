{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Methods Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 CPD approximation by ALS\n",
    "\n",
    "Implement the alternating-least-squares (ALS) algorithm for the low-rank approximation of a tensor of dimension $d \\in \\N$ at least two and mode sizes $n_1, \\dots, n_d \\in \\N$. For $R, r \\in \\N$ such that $r < R$, the implementation should take, as input parameters, a rank-$R$ CPD of the tensor given in the form of matrices $U_k \\in \\R^{n_k \\times R}$ with $k ∈ \\{1, \\dots, d\\}$ and a rank-$r$ CPD of the initial guess given in the form of matrices $V_k \\in \\R^{n_k \\times r}$ with $k \\in \\{1, \\dots, d\\}$. The number of iterations to be performed should be an input parameter.\n",
    "\n",
    "The best-accuracy rank-$r$ least-squares approximation problem is based on the cost function given by\n",
    "$$ \\phi(V_1, \\dots, V_d) = \\| \\psi_r(V_1, \\dots, V_d) − \\psi_R(U_1, \\dots, U_d)\\|_F $$\n",
    "for all $V_k \\in \\R^{n_k \\times r}$ with $k \\in \\{1, \\dots, d\\}$, where $\\psi_r$ and $\\psi_R$ denote the CPD multilinear representation maps transforming CP decompositions of ranks $r$ and $R$ into tensors $\\R^{n_1 \\times \\dots \\times n_d}$.\n",
    "\n",
    "In your implementation, a single ALS iteration starting at a CPD given by $V_k \\in \\R^{n_k \\times r}$ with $k \\in \\{1, \\dots, d\\}$ should consists in updating $V_k$ for fixed $V_1, \\dots, V_{k−1}, V_{k+1}, \\dots, V_d$ with a solution of the optimization problem\n",
    "$$ \\phi(V_1, \\dots, V_d) \\to \\min_{V_k \\in \\R^{n_k \\times r}} $$\n",
    "sequentially for $k = 1, 2, . . . , d − 1, d, d − 1, d − 2, . . . , 3, 2$.\n",
    "\n",
    "An additional requirement is as follows: the cost of a single iteration should be linear with respect to $d$ (certain elementwise products of Gram matrices accumulating from the left and from the right should be stored, and exactly one of these should be updated at each step of a single iteration).\n",
    "\n",
    "Make sure that your implementation evaluates the above cost function $\\phi$, the 2-norm of $\\frac{1}{2} \\nabla \\phi^2$ and the two-norms of the $r$ CPD terms after each iteration and returns the history of the computed values alongside the final CP appproximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct CPD{T<:Number}\n",
    "    frames::Vector{Matrix{T}}\n",
    "    shape::NTuple{N,Integer} where {N}\n",
    "    rank::Integer\n",
    "    function CPD{T}(frames::Vector{Matrix{T}}) where T<:Number\n",
    "        shape = [size(U,1) for U in frames]\n",
    "        ranks = [size(U,2) for U in frames]\n",
    "\n",
    "        # non empty\n",
    "        if isempty(frames)\n",
    "            error(\"No frame matrices were provided.\")\n",
    "        end\n",
    "\n",
    "        # rank dimensions have to match and be > 0\n",
    "        if ranks[1] < 0\n",
    "            error(\"Rank has to be greater than 0.\")\n",
    "        end\n",
    "        if any(ranks .!= ranks[1])\n",
    "            error(\"Frame matrices do not share the same rank dimension.\")\n",
    "        end\n",
    "        \n",
    "        # mode dimensions have to be > 0\n",
    "        if any(shape .< 0)\n",
    "            error(\"Mode dimensions have to be greater than 0.\")\n",
    "        end\n",
    "\n",
    "        # create instance\n",
    "        new{T}(frames, Tuple(shape), ranks[1])\n",
    "    end\n",
    "end\n",
    "\n",
    "# defer element type from input\n",
    "CPD(frames::Vector{Matrix{T}}) where {T<:Number} = CPD{T}(frames)\n",
    "\n",
    "# basic functions\n",
    "Base.eltype(::Type{<:CPD{T}}) where {T} = T\n",
    "Base.ndims(A::CPD{T}) where {T} = length(A.frames)\n",
    "Base.size(A::CPD{T}) where {T} = A.shape\n",
    "Base.length(A::CPD{T}) where {T} = prod(size(A))\n",
    "rank(A::CPD{T}) where{T} = A.rank\n",
    "function Base.size(A::CPD{T}, k::Integer) where {T}\n",
    "    if k < 0\n",
    "        error(\"arraysize: dimension out of range\")\n",
    "    end\n",
    "    if k <= ndims(A)\n",
    "        return A.shape[k]\n",
    "    else\n",
    "        return 1\n",
    "    end\n",
    "end\n",
    "\n",
    "# construct tensor from CPD, implemented by Prof. Kazeev\n",
    "function totensor(A::CPD{T}) where {T}\n",
    "    d = ndims(A)\n",
    "    n = size(A)\n",
    "    r = rank(A)\n",
    "    S = zeros(T, prod(n))\n",
    "    for α = 1:r\n",
    "        B = A.frames[1][:,α]\n",
    "        for k = 2:1:d\n",
    "            B = kron(A.frames[k][:,α], B)\n",
    "        end\n",
    "        S .+= B\n",
    "    end\n",
    "    reshape(S, n...)\n",
    "end\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Khatri_Rao (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function Khatri_Rao(A::AbstractMatrix, B::AbstractMatrix)\n",
    "    i, k = size(A)\n",
    "    j, kb = size(B)\n",
    "    @assert k == kb \"Column dimensions do not match!\"\n",
    "\n",
    "    TA = eltype(A)\n",
    "    TB = eltype(B)\n",
    "    T = promote_type(TA, TB)\n",
    "    C = similar(A, T, (i*j, k))\n",
    "\n",
    "    for t = 1:k\n",
    "        C[:, t] = kron(A[:,t], B[:,t])\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ALS(A::CPD, X0::CPD, max_iter::Integer)\n",
    "    d = ndims(A)\n",
    "    n = size(A)\n",
    "    R = rank(A)\n",
    "    r = rank(X0)\n",
    "    TA = eltype(A)\n",
    "    TX = eltype(X0)\n",
    "    T = promote_type(TA, TX)\n",
    "\n",
    "    @assert (d == ndims(X0)) && all(n == size(X0)) \"Mode dimensions of initial guess do not match given tensor.\"\n",
    "    @assert r < R \"Rank of initial guess has to be smaller than that given tensor.\"\n",
    "    @assert max_iter > 0 \"Number of maximum iterations has to be greater than 0, got $max_iter\"\n",
    "    \n",
    "    S = totensor(A)\n",
    "    X = copy(X0.frames)\n",
    "    norms = []\n",
    "    \n",
    "    for _ = 1:max_iter\n",
    "        H_l = Matrix{T}(I, r, r)\n",
    "        #H_r = foldl((.*), [X[i]' * X[i] for i = 2:d])\n",
    "        for k = 1:d\n",
    "            #H_l = k == 1 ? Matrix{T}(I, r, r) : foldl((.*), [X[i]' * X[i] for i = 1:(k-1)])\n",
    "            H_l = H_l .* (X[k]' * X[k])\n",
    "            H_r = k == d ? Matrix{T}(I, r, r) : foldl((.*), [X[i]' * X[i] for i = (k+1):d])\n",
    "            #H_r = H_r ./ (X[k]' * X[k])\n",
    "            H = H_l .* H_r\n",
    "\n",
    "            if k == 1\n",
    "                KR = foldl(Khatri_Rao, X[(k+1):d])\n",
    "            elseif k == d\n",
    "                KR = foldl(Khatri_Rao, X[1:(k-1)])\n",
    "            else\n",
    "                KR_left = foldl(Khatri_Rao, X[1:(k-1)])\n",
    "                KR_right = foldl(Khatri_Rao, X[(k+1):d])\n",
    "                KR = Khatri_Rao(KR_left, KR_right)\n",
    "            end\n",
    "\n",
    "            # unfolding matrix\n",
    "            p = prod(n[1:k-1])\n",
    "            q = prod(n[k+1:end])\n",
    "            B = reshape(S, p, n[k], q)\n",
    "            B = permutedims(B, [2,1,3])\n",
    "            B = reshape(B, n[k], p*q)\n",
    "\n",
    "            X[k] = B * KR * H'\n",
    "            X[k] = X[k] / norm(X[k])\n",
    "        end\n",
    "        \n",
    "        val = norm(totensor(CPD(X)) + S)\n",
    "        push!(norms, val)\n",
    "    end\n",
    "\n",
    "    return CPD(X), norms\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "n = (40,50,60)\n",
    "R = 30\n",
    "r = 20\n",
    "U = Vector{Matrix{Float64}}(undef, d)\n",
    "V = Vector{Matrix{Float64}}(undef, d)\n",
    "for k = 1:d\n",
    "    U[k] = rand(n[k], R)\n",
    "    V[k] = rand(n[k], r)\n",
    "end\n",
    "\n",
    "A = totensor(CPD(U))\n",
    "B_CPD, norms = ALS(CPD(U), CPD(V), 10)\n",
    "B = totensor(B_CPD)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " 1331.4118994301425\n",
       " 1332.1065808629373\n",
       " 1332.1181281531951\n",
       " 1332.118128153195\n",
       " 1332.118128153195\n",
       " 1332.118128153195\n",
       " 1332.118128153195\n",
       " 1332.118128153195\n",
       " 1332.118128153195\n",
       " 1332.118128153195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 ALS approximation of the matrix-multiplication tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmultensorcpd (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" from master solution of homework 2 \"\"\"\n",
    "\n",
    "function matmultensor(::Type{T}, n::Int) where T<:Number\n",
    "    @assert n ≥ 2\n",
    "    S = zeros(T, n, n, n, n, n, n) # rowA, colA, rowB, colB, rowC, colC\n",
    "    for i ∈ 1:n, j ∈ 1:n, k ∈ 1:n\n",
    "        # C_{ij} = \\sum_{k=1}^n A_{ik} B_{kj}\n",
    "        S[i,k,k,j,i,j] = 1\n",
    "    end\n",
    "    reshape(S, n^2, n^2, n^2)\n",
    "end\n",
    "\n",
    "function matmultensorcpd(::Type{T}, n::Int) where T<:Number\n",
    "    @assert n ≥ 2\n",
    "    U = zeros(T, n, n, n, n, n)\n",
    "    V = zeros(T, n, n, n, n, n)\n",
    "    W = zeros(T, n, n, n, n, n)\n",
    "    for i ∈ 1:n, j ∈ 1:n, k ∈ 1:n\n",
    "        # C_{ij} = \\sum_{k=1}^n A_{ik} B_{kj}\n",
    "        U[i,k,i,j,k] = 1\n",
    "        V[k,j,i,j,k] = 1\n",
    "        W[i,j,i,j,k] = 1\n",
    "    end\n",
    "    U = reshape(U, n^2, n^3)\n",
    "    V = reshape(V, n^2, n^3)\n",
    "    W = reshape(W, n^2, n^3)\n",
    "    [U,V,W]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4×4 Array{Float64, 3}:\n",
       "[:, :, 1] =\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 2] =\n",
       " 0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0\n",
       "\n",
       "[:, :, 3] =\n",
       " 0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 4] =\n",
       " 0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M2 = matmultensor(Float64, 2)\n",
    "r2 = 7\n",
    "\n",
    "M3 = matmultensor(Float64, 3)\n",
    "r3 = 23\n",
    "\n",
    "M4 = matmultensor(Float64, 4)\n",
    "r4 = 49\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 ALS approximation of a Laplace-like tensor tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 0]\n",
    "b = [0, 1]\n",
    "U1 = hcat(b, a, a)\n",
    "U2 = hcat(a, b, a)\n",
    "U3 = hcat(a, a, b)\n",
    "T = reshape(kron(b, a, a) + kron(a, b, a) + kron(a, a, b), 2, 2, 2) # Laplace-like tensor\n",
    "\n",
    "# initial guess\n",
    "V = Vector{Matrix{Float64}}(undef, 3)\n",
    "for k = 1:3\n",
    "    V[k] = rand(2, 2)\n",
    "end\n",
    "\n",
    "T_CPD, norms = ALS(CPD([U1, U2, U3]), CPD(V), 1000000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000-element Vector{Any}:\n",
       " 2.289743494090558\n",
       " 2.5105255286283126\n",
       " 2.5116206529684812\n",
       " 2.511813956347031\n",
       " 2.511846884189029\n",
       " 2.5118515443072584\n",
       " 2.511852068470737\n",
       " 2.5118521158561244\n",
       " 2.5118521200953867\n",
       " 2.511852120673332\n",
       " ⋮\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218\n",
       " 2.511852120798218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
